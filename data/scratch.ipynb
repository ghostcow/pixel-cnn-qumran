{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5412, 7216)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   0,   0, ..., 383, 383, 383]), array([359, 360, 361, ..., 381, 382, 383]))\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "new_x_gen = []\n",
    "for i in range(args.nr_gpu):\n",
    "    with tf.device('/gpu:%d' % i):\n",
    "        gen_par = model(xs[i], h_sample[i], ema=ema, dropout_p=0, **model_opt)\n",
    "        new_x_gen.append(nn.sample_from_discretized_mix_logistic(gen_par, args.nr_logistic_mix))\n",
    "def sample_from_model(sess):\n",
    "    x_gen = [samples[i] for i in range(args.nr_gpu)]\n",
    "    for yi in range(obs_shape[0]):\n",
    "        for xi in range(obs_shape[1]):\n",
    "            new_x_gen_np = sess.run(new_x_gen, {xs[i]: x_gen[i] for i in range(args.nr_gpu)})\n",
    "            for i in range(args.nr_gpu):\n",
    "                x_gen[i][:,yi,xi,:] = new_x_gen_np[i][:,yi,xi,:]*(1-masks[:,yi,xi,:])+x_gen[i][:,yi,xi,:]*masks[:,yi,xi,:]\n",
    "    return np.concatenate(x_gen, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# train for one epoch\n",
    "train_losses = []\n",
    "for d in tqdm(train_data):\n",
    "    feed_dict = make_feed_dict(d)\n",
    "    # forward/backward/update model on each gpu\n",
    "    lr *= args.lr_decay\n",
    "    feed_dict.update({ tf_lr: lr })\n",
    "    l,_ = sess.run([bits_per_dim, optimizer], feed_dict)\n",
    "    train_losses.append(l)\n",
    "train_loss_gen = np.mean(train_losses)\n",
    "\n",
    "# compute likelihood over test data\n",
    "test_losses = []\n",
    "for d in test_data:\n",
    "    feed_dict = make_feed_dict(d)\n",
    "    l = sess.run(bits_per_dim_test, feed_dict)\n",
    "    test_losses.append(l)\n",
    "test_loss_gen = np.mean(test_losses)\n",
    "test_bpd.append(test_loss_gen)\n",
    "\n",
    "# log progress to console\n",
    "print(\"Iteration %d, time = %ds, train bits_per_dim = %.4f, test bits_per_dim = %.4f\" % (epoch, time.time()-begin, train_loss_gen, test_loss_gen))\n",
    "sys.stdout.flush()\n",
    "\n",
    "if epoch % args.save_interval == 0:\n",
    "\n",
    "    \n",
    "    for d in test_data:\n",
    "        feed_dict = make_feed_dict(d)\n",
    "        l = sess.run(bits_per_dim_test, feed_dict)\n",
    "        test_losses.append(l)\n",
    "    \n",
    "    # generate samples from the model\n",
    "    sample_x = sample_from_model(sess)\n",
    "    img_tile = plotting.img_tile(sample_x[:int(np.floor(np.sqrt(args.batch_size*args.nr_gpu))**2)], aspect_ratio=1.0, border_color=1.0, stretch=True)\n",
    "    img = plotting.plot_img(img_tile, title=args.data_set + ' samples')\n",
    "    plotting.plt.savefig(os.path.join(args.save_dir,'%s_sample%d.png' % (args.data_set, epoch)))\n",
    "    plotting.plt.close('all')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
